type(annot)
class(annot)
class(dat)
dat <- merge(S1,S2, by='parcel')
dat <- merge(S1,S2, by='parcel')
dat %>% slice(order(factor(parcel, levels = annot['parcel'])))
dat <- dat[,c('parcel', 'SZ_mean_base', 'SZ_SD_base', 'SZ_mean_6weeks', 'SZ_SD_6weeks')]
dat
dat %>% arrange(factor('parcel', levels = annot['parcel']))
dat <- merge(annot, dat, by='parcel' )
dat
dat <- merge(S1,S2, by='parcel')
dat <- left_join(annot, dat, by='parcel' )
dat
annot['pacel']
annot['parcel']
dat <- merge(S1,S2, by='parcel')
dat['parcel']
S1 <- S1 %>% mutate(ROI = lower(ROI)) %>%
unite(parcel, c('Hemisphere', 'ROI'))
S1 <- S1 %>% mutate(ROI = tolower(ROI)) %>%
unite(parcel, c('Hemisphere', 'ROI'))
S1 <- S1 %>% mutate(ROI = tolower('ROI')) %>%
unite(parcel, c('Hemisphere', 'ROI'))
# S1
S1<-S1 %>% mutate(
SZ_mean_base =as.numeric(sapply(strsplit(Thickness.SZ..Mean..SD.., ' '), `[`, 1)),
SZ_SD_base =sapply(strsplit(Thickness.SZ..Mean..SD.., ' '), `[`, 2)
) %>%
mutate(
SZ_SD_base = as.numeric(gsub('\\)', '', gsub('\\(', '', SZ_SD_base)))
)
S1 <- S1 %>% mutate(ROI = tolower('ROI')) %>%
unite(parcel, c('Hemisphere', 'ROI'))
S1 <- S1 %>% mutate(ROI = tolower('ROI'))
rlang::last_trace()
S1
# S1
S1<-S1 %>% mutate(
SZ_mean_base =as.numeric(sapply(strsplit(Thickness.SZ..Mean..SD.., ' '), `[`, 1)),
SZ_SD_base =sapply(strsplit(Thickness.SZ..Mean..SD.., ' '), `[`, 2)
) %>%
mutate(
SZ_SD_base = as.numeric(gsub('\\)', '', gsub('\\(', '', SZ_SD_base)))
)
S1 <- S1 %>% mutate(ROI = tolower('ROI'))
S1
S1 = read.csv(paste0(base, '/data/Jessen/Jessen_S1_Cortical_ROIS_at_baseline.csv'))
# S1
S1<-S1 %>% mutate(
SZ_mean_base =as.numeric(sapply(strsplit(Thickness.SZ..Mean..SD.., ' '), `[`, 1)),
SZ_SD_base =sapply(strsplit(Thickness.SZ..Mean..SD.., ' '), `[`, 2)
) %>%
mutate(
SZ_SD_base = as.numeric(gsub('\\)', '', gsub('\\(', '', SZ_SD_base)))
)
S1 <- S1 %>% mutate(ROI = tolower('ROI'))
S1
base = '/Users/laurituominen/Documents/Research/AP_cortical_thickness_v2'
S1 = read.csv(paste0(base, '/data/Jessen/Jessen_S1_Cortical_ROIS_at_baseline.csv'))
S2 = read.csv(paste0(base, '/data/Jessen/Jessen_S2_Cortical_ROIS_at_six-weeks.csv'))
S3 =  read.csv(paste0(base, '/data/Jessen/Jessen_S3_ROI_symmetrized_change.csv'))
annot = read.csv(paste0(base, '/annot/atlas-desikankilliany.csv'))
annot <- annot[annot['structure']=='cortex',]
annot$parcel<- paste0(annot$hemisphere, '_', annot$label)
# S1
S1<-S1 %>% mutate(
SZ_mean_base =as.numeric(sapply(strsplit(Thickness.SZ..Mean..SD.., ' '), `[`, 1)),
SZ_SD_base =sapply(strsplit(Thickness.SZ..Mean..SD.., ' '), `[`, 2)
) %>%
mutate(
SZ_SD_base = as.numeric(gsub('\\)', '', gsub('\\(', '', SZ_SD_base)))
)
S1 <- S1 %>% mutate(ROI = tolower(ROI))
S1$ROI
S1 <- S1 %>% mutate(ROI = tolower(ROI)) %>%
unite(parcel, c('Hemisphere', 'ROI'))
S1$parcel
# S2
S2<-S2 %>% mutate(
SZ_mean_6weeks =as.numeric(sapply(strsplit(Thickness.SZ..Mean..SD.., ' '), `[`, 1)),
SZ_SD_6weeks =sapply(strsplit(Thickness.SZ..Mean..SD.., ' '), `[`, 2)
) %>%
mutate(
SZ_SD_6weeks = as.numeric(gsub('\\)', '', gsub('\\(', '', SZ_SD_6weeks)))
)
S2 <- S2 %>% mutate(ROI = tolower(ROI)) %>%
unite(parcel, c('Hemisphere', 'ROI'))
bN = 56 # N of participants at t1
fN = 41 # N of participants at t2
# treating these as independent samples
dat <- merge(S1,S2, by='parcel')
dat <- left_join(annot, dat, by='parcel' )
dat <- dat[,c('parcel', 'SZ_mean_base', 'SZ_SD_base', 'SZ_mean_6weeks', 'SZ_SD_6weeks')]
dat
# SD pooled sp = sqrt( ((n1-1)*SD1^2 + (n2 -1)*SD2^2) / (n1+n2-2)
dat <- dat %>% mutate(
sp = sqrt( ((bN-1)*SZ_SD_base^2 + (fN -1)*SZ_SD_6weeks^2) / (bN+fN-2)),
J = 1- (3 / (4 * (bN+fN-2) -1))
) %>%
mutate(
cohen_d = ( ( SZ_mean_6weeks- SZ_mean_base)/ sp)
) %>%
mutate(
hedges_g = J * cohen_d
)
write_csv(dat, paste0(base, '/data/jessen/jessen_effectsize.csv'))
library(pwr)
result <- pwr.t.test(d = 1.2, sig.level = 0.05, power = 0.80, type = "paired", alternative = "two.sided")
print(result)
pwr.t.test(d = 1, sig.level = 0.05, power = 0.80, type = "paired", alternative = "two.sided")
pwr.t.test(d = 0.8, sig.level = 0.05, power = 0.80, type = "paired", alternative = "two.sided")
65000 *4
library(tidyverse)
# load data
base = '/Users/laurituominen/Documents/Research/AP_cortical_thickness_v2'
lh_file = paste0(base, '/data/CLZ44/stats/lh_aparc_stats.txt')
rh_file = paste0(base, '/data/CLZ44/stats/rh_aparc_stats.txt')
lh= read_delim(lh_file, delim='\t')
rh = read_delim(rh_file, delim='\t')
lh
# parcels
parcels = c('bankssts_thickness','caudalanteriorcingulate_thickness',
'caudalmiddlefrontal_thickness', 'cuneus_thickness',
'entorhinal_thickness', 'fusiform_thickness',
'inferiorparietal_thickness', 'inferiortemporal_thickness',
'isthmuscingulate_thickness', 'lateraloccipital_thickness',
'lateralorbitofrontal_thickness', 'lingual_thickness',
'medialorbitofrontal_thickness', 'middletemporal_thickness',
'parahippocampal_thickness', 'paracentral_thickness',
'parsopercularis_thickness', 'parsorbitalis_thickness',
'parstriangularis_thickness', 'pericalcarine_thickness',
'postcentral_thickness', 'posteriorcingulate_thickness',
'precentral_thickness', 'precuneus_thickness',
'rostralanteriorcingulate_thickness',
'rostralmiddlefrontal_thickness', 'superiorfrontal_thickness',
'superiorparietal_thickness', 'superiortemporal_thickness',
'supramarginal_thickness', 'frontalpole_thickness',
'temporalpole_thickness', 'transversetemporal_thickness',
'insula_thickness')
lh
dat <- merge(lh, rh)
dat
lh <- lh %>% mutate(
STUDYID = sapply(strsplit(rh.aparc.thickness, "_"), `[`, 1),
)
lh <- lh %>% mutate(
STUDYID = sapply(strsplit(lh.aparc.thickness, "_"), `[`, 1),
)
lh
lh$STUDYID
rh
lh <- lh %>% mutate(
STUDYID = sapply(strsplit(lh.aparc.thickness, "_"), `[`, 1),
timepoint = sapply(strsplit(lh.aparc.thickness, "_"),
function(x) {
p4 <- x[4]
split_by_dot <- strsplit(p4, "\\.")[[1]]
split_by_dot[1]
}
) )
lh$timepoint
lh <- lh %>% mutate(
STUDYID = sapply(strsplit(lh.aparc.thickness, "_"), `[`, 1),
timepoint = sapply(strsplit(lh.aparc.thickness, "_"),
function(x) {
p4 <- x[2]
split_by_dot <- strsplit(p4, "\\.")[[1]]
split_by_dot[1]
}
) )
lh$timepoint
rh <- rh %>% mutate(
STUDYID = sapply(strsplit(rh.aparc.thickness, "_"), `[`, 1),
timepoint = sapply(strsplit(rh.aparc.thickness, "_"),
function(x) {
p4 <- x[2]
split_by_dot <- strsplit(p4, "\\.")[[1]]
split_by_dot[1]
}
) )
dat <- merge(lh, rh, by='STUDYID')
dat
cor(dat$timepoint.x,dat$timepoint.y)
dataframe(dat$timepoint.x,dat$timepoint.y)
dat$timepoint.x,dat$timepoint.y)
dat$timepoint.x,dat$timepoint.y
data.frame( dat$timepoint.x,dat$timepoint.y)
dat
dat <- merge(lh, rh, by=c('STUDYID', 'timepoint'))
dat
dat
data.frame( dat$timepoint.x,dat$timepoint.y)
View(dat)
dat <- dat %>% relocate("STUDYID", "timepoint","lh.aparc.thickness","rh.aparc.thickness")
dat
dat[,1:4]
names(dat)
dat <- dat %>% relocate("STUDYID", "timepoint","lh.aparc.thickness","rh.aparc.thickness")  %>%
select(!containsc(rh.aparc.thickness, lh.aparc.thickness, BrainSegVolNotVent.y, PlotLabel, eTIV,eTIV))
dat <- dat %>% relocate("STUDYID", "timepoint","lh.aparc.thickness","rh.aparc.thickness")  %>%
select(!contains(c(rh.aparc.thickness, lh.aparc.thickness, BrainSegVolNotVent.y, PlotLabel, eTIV,eTIV)))
dat <- dat %>% relocate("STUDYID", "timepoint","lh.aparc.thickness","rh.aparc.thickness")  %>%
select(!contains(c("rh.aparc.thickness", "lh.aparc.thickness", "BrainSegVolNotVent","eTIV")))
dat
dat$timepoint_num <- ifelse(timepoint=='PRCL', 0, 1 )
dat$timepoint_num <- ifelse(dat$timepoint=='PRCL', 0, 1 )
dat
dat <- merge(lh, rh, by=c('STUDYID', 'timepoint'))
dat$timepoint_num <- ifelse(dat$timepoint=='PRCL', 0, 1 )
dat <- dat %>% relocate("STUDYID", "timepoint","timepoint_num", "lh.aparc.thickness","rh.aparc.thickness")  %>%
select(!contains(c("rh.aparc.thickness", "lh.aparc.thickness", "BrainSegVolNotVent","eTIV")))
dat
?summarise
dat %>% group_by("timepoint") %>%
summarize(mean=mean(), sd = sd()
)
dat %>% group_by("timepoint") %>%
summarize_all(mean(), sd())
dat %>% group_by("timepoint") %>%
summarize_all(mean, sd)
dat %>% group_by(timepoint) %>%
summarize(
across(
.cols = everything(),
.fns = list(mean = mean, sd = sd)
)
)
dat
dat %>% select(!c("STUDYID", "timepoint_num")) %>%
group_by(timepoint) %>%
summarize(
across(
.cols = everything(),
.fns = list(mean = mean, sd = sd)
)
)
stats <- dat %>% select(!c("STUDYID", "timepoint_num")) %>%
group_by(timepoint) %>%
summarize(
across(
.cols = everything(),
.fns = list(mean = mean, sd = sd)
)
)
stats
stats %>%
pivot_longer(
everything(),
cols_vary = "slowest",
names_to = c(".value", "set"),
names_pattern = "(.)(.)"
)
stats
stats <- stats %>% pivot_longer()
stats <- stats %>% pivot_longer(
!timepoint, names_to = "measure", values_to = "value"
)
stats
stats <- dat %>% select(!c("STUDYID", "timepoint_num")) %>%
group_by(timepoint) %>%
summarize(
across(
.cols = everything(),
.fns = list(mean = mean, sd = sd)
)
)
stats
dat
stats
stats_l <- stats %>% pivot_longer(
!timepoint, names_to = "measure", values_to = "value"
)
stats_l
stats %>% pivot_longer(
cols = -timepoint,
names_to = c("region", "metric"),     # split into two parts
names_pattern = "(.*)_(mean|sd)$",    # region is everything before _mean or _sd
values_to = "value"
)
stats %>% pivot_longer(
cols = -timepoint,
names_to = c("region", "metric"),     # split into two parts
names_pattern = "(.*)_(mean|sd)$",    # region is everything before _mean or _sd
values_to = "value"
) %>%
# Step 2: pivot back to wide
pivot_wider(
id_cols      = region,
names_from   = c(timepoint, metric),
values_from  = value
) %>%
# Step 3: optionally rename to your desired column names
rename(
mean_POCL = POCL_mean,
sd_POCL   = POCL_sd,
mean_PRCL = PRCL_mean,
sd_PRCL   = PRCL_sd
)
# reorg
stats <- stats %>% pivot_longer(
cols = -timepoint,
names_to = c("region", "metric"),
names_pattern = "(.*)_(mean|sd)$",
values_to = "value"
) %>%
pivot_wider(
id_cols      = region,
names_from   = c(timepoint, metric),
values_from  = value
) %>%
rename(
mean_POCL = POCL_mean,
sd_POCL   = POCL_sd,
mean_PRCL = PRCL_mean,
sd_PRCL   = PRCL_sd
)
stats
stats <- stats %>%
mutate(
cohen_d = (mean_POCL - mean_PRCL) /
sqrt( (sd_PRCL^2 + sd_POCL^2) / 2 )
) %>%
mutate(
hedges_g =  cohen_d * (1 - 3 / (4 * 84 - 9))
)
stats
file=paste0(base, '/data/CLZ44/stats/parcelwise_effectsize.csv')
write.csv(df, file=file, row.names = FALSE)
file=paste0(base, '/data/CLZ44/stats/parcelwise_effectsize.csv')
write.csv(stats, file=file, row.names = FALSE)
# load data
base = '/Users/laurituominen/Documents/Research/AP_cortical_thickness_v2'
lh_file = paste0(base, '/data/CLZ44/stats/lh_aparc_stats.txt')
rh_file = paste0(base, '/data/CLZ44/stats/rh_aparc_stats.txt')
lh= read_delim(lh_file, delim='\t')
rh = read_delim(rh_file, delim='\t')
# extract STUDYID and timepoint from filename
lh <- lh %>% mutate(
STUDYID = sapply(strsplit(lh.aparc.thickness, "_"), `[`, 1),
timepoint = sapply(strsplit(lh.aparc.thickness, "_"),
function(x) {
p4 <- x[2]
split_by_dot <- strsplit(p4, "\\.")[[1]]
split_by_dot[1]
}
) )
rh <- rh %>% mutate(
STUDYID = sapply(strsplit(rh.aparc.thickness, "_"), `[`, 1),
timepoint = sapply(strsplit(rh.aparc.thickness, "_"),
function(x) {
p4 <- x[2]
split_by_dot <- strsplit(p4, "\\.")[[1]]
split_by_dot[1]
}
) )
# merge
dat <- merge(lh, rh, by=c('STUDYID', 'timepoint'))
dat <- dat %>% relocate("STUDYID", "timepoint")  %>%
select(!contains(c("rh.aparc.thickness", "lh.aparc.thickness", "BrainSegVolNotVent","eTIV")))
names(dat)
library(tidyverse)
# load data
base = '/Users/laurituominen/Documents/Research/AP_cortical_thickness_v2'
lh_file = paste0(base, '/data/CLZ44/stats/lh_aparc_stats.txt')
rh_file = paste0(base, '/data/CLZ44/stats/rh_aparc_stats.txt')
lh= read_delim(lh_file, delim='\t')
rh = read_delim(rh_file, delim='\t')
# extract STUDYID and timepoint from filename
lh <- lh %>% mutate(
STUDYID = sapply(strsplit(lh.aparc.thickness, "_"), `[`, 1),
timepoint = sapply(strsplit(lh.aparc.thickness, "_"),
function(x) {
p4 <- x[2]
split_by_dot <- strsplit(p4, "\\.")[[1]]
split_by_dot[1]
}
) )
rh <- rh %>% mutate(
STUDYID = sapply(strsplit(rh.aparc.thickness, "_"), `[`, 1),
timepoint = sapply(strsplit(rh.aparc.thickness, "_"),
function(x) {
p4 <- x[2]
split_by_dot <- strsplit(p4, "\\.")[[1]]
split_by_dot[1]
}
) )
# merge
dat <- merge(lh, rh, by=c('STUDYID', 'timepoint'))
dat <- dat %>% relocate("STUDYID", "timepoint")  %>%
select(!contains(c("rh.aparc.thickness", "lh.aparc.thickness", "lh_MeanThickness_thickness" ,"rh_MeanThickness_thickness" ,"BrainSegVolNotVent","eTIV")))
names(dat)
# gather means and sd's
stats <- dat %>% select(!c("STUDYID", "timepoint_num")) %>%
group_by(timepoint) %>%
summarize(
across(
.cols = everything(),
.fns = list(mean = mean, sd = sd)
)
)
# gather means and sd's
stats <- dat %>% select(!c("STUDYID")) %>%
group_by(timepoint) %>%
summarize(
across(
.cols = everything(),
.fns = list(mean = mean, sd = sd)
)
)
# reorganize
stats <- stats %>% pivot_longer(
cols = -timepoint,
names_to = c("region", "metric"),
names_pattern = "(.*)_(mean|sd)$",
values_to = "value"
) %>%
pivot_wider(
id_cols      = region,
names_from   = c(timepoint, metric),
values_from  = value
) %>%
rename(
mean_POCL = POCL_mean,
sd_POCL   = POCL_sd,
mean_PRCL = PRCL_mean,
sd_PRCL   = PRCL_sd
)
stats
stats <- stats %>% relocate(region, mean_PRCL, sd_PRCL, mean_POCL, sd_POCL)
stats
# calculate effect sizes
stats <- stats %>%
mutate(
cohen_d = (mean_POCL - mean_PRCL) /
sqrt( (sd_PRCL^2 + sd_POCL^2) / 2 )
) %>%
mutate(
hedges_g =  cohen_d * (1 - 3 / (4 * 84 - 9))
)
file=paste0(base, '/data/CLZ44/stats/parcelwise_effectsize.csv')
write.csv(stats, file=file, row.names = FALSE)
library(tidyverse)
# load data
base = '/Users/laurituominen/Documents/Research/AP_cortical_thickness_v2'
lh_file = paste0(base, '/data/CLZ44/stats/lh_aparc_stats.txt')
rh_file = paste0(base, '/data/CLZ44/stats/rh_aparc_stats.txt')
lh= read_delim(lh_file, delim='\t')
rh = read_delim(rh_file, delim='\t')
# extract STUDYID and timepoint from filename
lh <- lh %>% mutate(
STUDYID = sapply(strsplit(lh.aparc.thickness, "_"), `[`, 1),
timepoint = sapply(strsplit(lh.aparc.thickness, "_"),
function(x) {
p4 <- x[2]
split_by_dot <- strsplit(p4, "\\.")[[1]]
split_by_dot[1]
}
) )
rh <- rh %>% mutate(
STUDYID = sapply(strsplit(rh.aparc.thickness, "_"), `[`, 1),
timepoint = sapply(strsplit(rh.aparc.thickness, "_"),
function(x) {
p4 <- x[2]
split_by_dot <- strsplit(p4, "\\.")[[1]]
split_by_dot[1]
}
) )
# merge
dat <- merge(lh, rh, by=c('STUDYID', 'timepoint'))
dat <- dat %>% relocate("STUDYID", "timepoint")  %>%
select(!contains(c("rh.aparc.thickness", "lh.aparc.thickness", "lh_MeanThickness_thickness" ,"rh_MeanThickness_thickness" ,"BrainSegVolNotVent","eTIV")))
# gather means and sd's
stats <- dat %>% select(!c("STUDYID")) %>%
group_by(timepoint) %>%
summarize(
across(
.cols = everything(),
.fns = list(mean = mean, sd = sd)
)
)
# reorganize
stats <- stats %>% pivot_longer(
cols = -timepoint,
names_to = c("parcel", "metric"),
names_pattern = "(.*)_(mean|sd)$",
values_to = "value"
) %>%
pivot_wider(
id_cols      = parcel,
names_from   = c(timepoint, metric),
values_from  = value
) %>%
rename(
mean_POCL = POCL_mean,
sd_POCL   = POCL_sd,
mean_PRCL = PRCL_mean,
sd_PRCL   = PRCL_sd
)
stats <- stats %>% relocate(parcel, mean_PRCL, sd_PRCL, mean_POCL, sd_POCL)
# calculate effect sizes
stats <- stats %>%
mutate(
cohen_d = (mean_POCL - mean_PRCL) /
sqrt( (sd_PRCL^2 + sd_POCL^2) / 2 )
) %>%
mutate(
hedges_g =  cohen_d * (1 - 3 / (4 * 84 - 9))
)
stats
file=paste0(base, '/data/CLZ44/stats/parcelwise_effectsize.csv')
write.csv(stats, file=file, row.names = FALSE)
